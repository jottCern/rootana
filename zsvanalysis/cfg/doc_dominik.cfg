options {
   blocksize 10000        ; number of events to process in one go. Should be set to a value s.t. it takes ~O(1) seconds to process.
                ; Ignored in local mode.
   output_dir rootfiles/full_more_sel4 ; directory for the output root files.
                ; If running in parallel mode, each worker uses output_dir/unmerged-${dataset.name}-${iworker}.root as the output rootfile.
                ; If merging is enabled, the final merged final result will be into one large root file  output_dir/${dataset.name}.root; if merging is not enabled,
                ;     the files of successfull workers are renamed to output_dir/${dataset.name}-${iworker}.root.
                ; For local, non-parallel mode, output is written directly to output-dir/${dataset.name}.root
   library libzsvanalysis.so ; library to load. This will be searched in: the current directory and where the executable is located plus exepath../lib/
                             ; more than one "library" statement is possible: the libraries will be loaded in order.
   
   searchpath /afs/desy.de/user/o/ottjoc/xxl-af-cms/zsv-cmssw/CMSSW_5_3_14_patch2/ ; where to look for files (including libraries). More than one 'searchpath' statement is possible.
   
   ; mergemode workers ; controls where the merging of the "unmerged-..." output root files takes place. Allowed values are:
                       ; - "workers": in this case, the merging is done two files at a time, recursively, on the workers.
                       ; - "master" (default): The merging is done in one large step on the master side after all files have been completely processed on the workers.
                       ; - "nomerge": do not merge output files; instead rename them to 'output_dir/${dataset.name}-${iworker}.root'

   ; output_max_filesize  1.0 ; maximum output file sizes in GB for the workers. If reaching this limit, a new output file is created,
                              ; output-dir/unmerged-${dataset.name}-${iworker}-${ifile}.root. Implies mergemode = nomerge (even if filesize limit is not reached).
                              ; note that the maximum filesize will only be enforced approximately: due to buffering, the current filesize is not
                              ; known exactly until actually written to disk.

   ; ** debugging options, usually not needed:

   ; keep_unmerged true       ; keep unmerged-* files (in addition to the merged one).
   ; maxevents_hint 500000    ; approximate maximum number of events to process.
}

logger {
    ; the filename pattern for the log file. %p is replaced with the pid, %h with the hostname and %T with the date+time.
    ; A message is written to the logfile if the the message loglevel exceeds the per-logger threshold (see below).
    ;logfile log-%T-%h-%p  ; log file name, relative to options.output_dir (or an absolute path). This is the default.

    ; set the threshold for messages that should be printed to stdout. A message will only be printed to stdout
    ; if the message exceeds both the logger threshold AND the stdout_threshold.
    ;stdout_threshold INFO  ; use one of DEBUG, INFO, WARNING, ERROR, QUIET, default is WARNING
    
    "" {
       threshold INFO
    }
    
    ; specific loggers can be set to another threshold like this:
    ;dra.Master { ; name of the logger. usually "<package>.<classname>" or "<package>.<function name>" but see source code / old logs to be sure.
    ;    threshold DEBUG
    ;}
    
    ;ra.root-utils.merge {
    ;    threshold DEBUG
    ;}
}


;dataset {
;   name dy ; dataset name; will be used in output filename
;   treename ZSVA/event ; name of the input event tree in the root file name
;   tags {
;      ; tags are completely user-defined key/value pairs with a unique key
;      ; they can be used in AnalysisModule::begin_dataset to make dataset-specific decisions / initializations.
;      ; Examples for useful tags are :
;      lumi 8624.1
;      is_real_data false
;   }
;   
;   ; provide file/file-pattern/sframe-xml-file statements to define which files belong to this dataset (more than one statement is possible in all cases):
;   file-pattern /nfs/dust/cms/user/ottjoc/gc-output/zplusjets-ntuple/ntuple/dyjets50*.root
;   
   ;file {
   ;  path /path/to/rootfile.root
   ;  nevents 1000 ; total number of events in file. Optional, default is auto-detect.
   ;  skip 200 ; skip first 200 events. Useful mainly for testing / debugging.
   ;}
   
   ; sframe-xml-file /afs/naf.desy.de/user/j/jott/SFrame/SFrameAnalysis/config/Samples_TTBSM53/TT_Powheg.xml  ; NOTE: does not do full xml parsing, just uses the file name of all lines with 'FileName=...'
   
   ; /DYJetsToLL_M-50_TuneZ2Star_8TeV-madgraph-tarball/Summer12_DR53X-PU_S10_START53_V7A-v1/AODSIM
   ; nevents: 30,459,503
   ; cross-section: 1177.3pb per lepton -> 3531.9pb total
;}

#include "ttbar.cfg"
;#include "dmu.cfg"

;#include "dyjets_incl.cfg"
;#include "dyjets_excl.cfg"


; to use the output event tree from a previous run, use:
;
;dataset_output_from "previous.cfg"
;
; This will use the "dataset" statements of the given configuration file (which should be given relative to the current config file),
; keeping the dataset name and tags, etc. but replacing the file name pattern such that the output of a run of that file is used.
; More than one "dataset_output_from" statement is possible. Recursive "dataset_output_from" (i.e. "previous.cfg" also uses "dataset_output_from")
; is supported, but still experimental.

modules {
    ; run these modules, in the order specified here
    setup_intree {
       type zsvtree
    }
    
    ;filter_duplicates {
    ;   type dcheck
    ;}
    
    muscale {
       type muscale
    }
    
    zp4 {
      type calc_zp4
    }
    
    filterdyincl {
       type filter_n_me_fs
       dy {
          nmin 2
          nmax 2
       }
    }
    
    mcweight { ; the name here is a user-defined name. It will be used in error messages.
      type mcweight ; type name must match the C++ class name
      ; more options can be set here; they are completely user-defined.
      target_lumi 19700.
    }
    
    pileup_weight {
       type pileup_reweight
       target /nfs/dust/cms/user/peiffer/Analysis53X_v3/PileUpHistos/MyDataPileupHistogram.root:pileup
    }
    
    sf {
       type dimusf
    }
    
    ; compute selections:
    sels {
        type Selections
        all {
            type PassallSelection
        }
        mll65 {
           type MllSelection
           mllmin 65
        }
        presel {
            type AndSelection
            selections "passed_reco_selection mll65"
        }
        bcand2 {
            type NBCandSelection
            nmin 2
            nmax 2
        }
        bcand1 {
            type NBCandSelection
            nmin 1
        }
        mll {
            type MllSelection
            mllmin 81
            mllmax 101
        }
        mllinvert {
            type AndNotSelection
            selections mll
        }
        met {
           type MetSelection
           metmax 50
           metmin -1
        }
        metinvert {
           type AndNotSelection
           selections met
        }
        
        ; the final selections for analysis or for control regions:
        final {
            type AndSelection
            selections "presel bcand2 mll met"
            cutflow_hname "cutflow" ; save as cutflow histogram
        }
        final_bef_met {
            type AndSelection
            selections "presel bcand2 mll"
        }
        one_bcand_bef_mll {
            type AndSelection
            selections "presel bcand1"
        }
        two_bcand_bef_mll {
            type AndSelection
            selections "presel bcand2"
        }
        no_bcand_rest {
            type AndSelection
            selections "presel mll"
        }
        final_mllinvert_premet {
           type AndSelection
           selections "presel bcand2 mllinvert"
        }
        final_mllinvert_metinvert {
           type AndSelection
           selections "presel bcand2 metinvert mllinvert"
           cutflow_hname "cutflow_cr"
        }
    }
    
    ; fill histograms, using the selections:
    histos {
       type HistFiller
       presel { ; name of the output directory. Per default, this is *also* the name of the event selection bit to decide which events are filled
          hists { ; declares that a Hists class configuration follows
              type BcandHists ; C++ class name of a class derived from 'Hists' and registered with REGISTER_HISTS
              mcb_minpt 30.   ; configuration parameters passed to the BcandHists class
          }
          hists BaseHists   ; short for hists { type BaseHists } in case no configuration is needed
       }
       final_mllinvert_premet {
          hists BaseHists
          hists {
              type BcandHists
              mcb_minpt 30.
          }
       }
       ; to make things shorter, one can set up many
       ; directories with the same configuration like this:
       _cfg {  ; first set the configuration to be used next
          hists BaseHists
          hists {
              type BcandHists
              mcb_minpt 30.
          }
       }
       ; now set up many directories, it will use the latest (!) "_cfg"
       _dirs "final_mllinvert_metinvert final final_bef_met one_bcand_bef_mll two_bcand_bef_mll"
       _dirs "no_bcand_rest" ; could also append that to the previous "_dirs" line
    }
}

